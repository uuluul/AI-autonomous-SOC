version: '3.9'

services:
  opensearch:
    image: opensearchproject/opensearch:2.14.0
    container_name: soc-staging-opensearch
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m"
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=admin
      - DISABLE_SECURITY_PLUGIN=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9200 >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12

  rabbitmq:
    image: rabbitmq:3.13-management
    container_name: soc-staging-rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: user
      RABBITMQ_DEFAULT_PASS: password
    ports:
      - "5672:5672"
      - "15672:15672"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 12

  mock-llm:
    build: .
    container_name: soc-staging-mock-llm
    command: ["python", "/app/src/mock_llm_server.py"]
    ports:
      - "18000:18000"

  app:
    build: .
    container_name: soc-staging-app
    command: ["python", "-u", "/app/src/run_pipeline.py"]
    environment:
      - ROLE=master
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - OPENSEARCH_USER=admin
      - OPENSEARCH_PASSWORD=admin
      - RABBITMQ_HOST=rabbitmq
      - LLM_PROVIDER=openai
      - OPENAI_API_KEY=dummy
      - OPENAI_BASE_URL=http://mock-llm:18000/v1
    volumes:
      - ./data:/app/data
      - ./out:/app/out
      - ./src:/app/src
    depends_on:
      opensearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  worker:
    build: .
    container_name: soc-staging-worker
    command: ["python", "-u", "/app/src/run_pipeline.py"]
    environment:
      - ROLE=worker
      - OPENSEARCH_HOST=opensearch
      - OPENSEARCH_PORT=9200
      - OPENSEARCH_USER=admin
      - OPENSEARCH_PASSWORD=admin
      - RABBITMQ_HOST=rabbitmq
      - LLM_PROVIDER=openai
      - OPENAI_API_KEY=dummy
      - OPENAI_BASE_URL=http://mock-llm:18000/v1
    volumes:
      - ./data:/app/data
      - ./out:/app/out
      - ./src:/app/src
    depends_on:
      opensearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      app:
        condition: service_started
