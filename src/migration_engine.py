"""
NeoVigil Migration Engine â€” Phase 3
====================================
Blue/Green Docker orchestration for zero-downtime container migration.

When an asset is under active attack (MTD score â‰¥ 85 + RBAC approval),
this engine:
  1. Spins up a GREEN replica on a new subnet
  2. Health-checks the replica until ready
  3. Updates the Nginx upstream to route traffic to Green
  4. Drains existing connections on the BLUE container
  5. Terminates Blue and cleans up the old network
  6. Deploys a Phase 2 honeypot at the old address

The attacker's IP-based kill chain is invalidated, and the old
address becomes a trap.
"""

import json
import logging
import os
import time
import uuid
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

# â”€â”€â”€ Lazy imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import docker
    import docker.errors
    import docker.types
    DOCKER_AVAILABLE = True
except ImportError:
    DOCKER_AVAILABLE = False
    logger.warning(
        "âš ï¸  Docker SDK not installed. Migration Engine operates in DRY-RUN mode."
    )

try:
    from src.setup_opensearch import get_opensearch_client
except ImportError:
    from setup_opensearch import get_opensearch_client

import pika

# â”€â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RABBITMQ_HOST = os.getenv("RABBITMQ_HOST", "rabbitmq")
PRODUCTION_NETWORK = "opensearch-net"
MTD_GREEN_PREFIX = "mtd-green"
MTD_AUDIT_INDEX = "mtd-audit-log"
MTD_MUTATIONS_INDEX = "mtd-active-mutations"
DECOY_DEPLOY_QUEUE = "decoy_deploy_tasks"

DEFAULT_DRAIN_TIMEOUT = int(os.getenv("MTD_DRAIN_TIMEOUT", "30"))
DEFAULT_HEALTH_TIMEOUT = int(os.getenv("MTD_HEALTH_TIMEOUT", "60"))
ROLLBACK_WINDOW_HOURS = int(os.getenv("MTD_ROLLBACK_HOURS", "4"))

# â”€â”€â”€ Criticality for priority ordering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_CRIT_SCORE = {
    "Critical": 1.0, "High": 0.8, "Medium": 0.5, "Low": 0.3, "Unknown": 0.4,
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Rollback Snapshot
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _capture_rollback_snapshot(container) -> dict:
    """
    Capture the current state of a container before migration
    so it can be restored during rollback.
    """
    attrs = container.attrs
    config = attrs.get("Config", {})
    host_config = attrs.get("HostConfig", {})
    network_settings = attrs.get("NetworkSettings", {}).get("Networks", {})

    return {
        "container_name": container.name,
        "container_id": container.id,
        "image": config.get("Image", ""),
        "labels": config.get("Labels", {}),
        "env_vars": config.get("Env", []),
        "networks": list(network_settings.keys()),
        "network_ip_map": {
            name: net.get("IPAddress", "")
            for name, net in network_settings.items()
        },
        "memory_limit": host_config.get("Memory", 0),
        "cpu_quota": host_config.get("CpuQuota", 0),
        "volumes": host_config.get("Binds", []),
        "ports": host_config.get("PortBindings", {}),
        "restart_policy": host_config.get("RestartPolicy", {}),
        "read_only": host_config.get("ReadonlyRootfs", False),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Green Network Creation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_green_network(
    docker_client: "docker.DockerClient",
    migration_id: str,
) -> "docker.models.networks.Network":
    """
    Create a new bridge network for the Green container.
    Unlike honeypot networks, this is NOT internal â€” it needs to
    serve production traffic via the Nginx proxy.
    """
    subnet_octet = (hash(migration_id) % 200) + 50
    net_name = f"{MTD_GREEN_PREFIX}-net-{migration_id[:8]}"

    network = docker_client.networks.create(
        name=net_name,
        driver="bridge",
        internal=False,     # Production traffic must reach Green
        check_duplicate=True,
        ipam=docker.types.IPAMConfig(
            pool_configs=[
                docker.types.IPAMPool(
                    subnet=f"172.31.{subnet_octet}.0/24",
                    gateway=f"172.31.{subnet_octet}.1",
                )
            ]
        ),
        labels={
            "neovigil.role": "mtd-green-network",
            "neovigil.migration_id": migration_id,
            "neovigil.created": datetime.utcnow().isoformat(),
        },
    )

    logger.info(
        f"ðŸŸ¢ Green network created: {net_name} "
        f"(subnet=172.31.{subnet_octet}.0/24)"
    )
    return network


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Migration Engine
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MigrationEngine:
    """
    Orchestrates Blue/Green container migration with zero-downtime.

    Migration flow:
      Phase A: Spin up Green (same image, env, volumes â€” new network)
      Phase B: Switch traffic (update Nginx upstream â†’ Green IP)
      Phase C: Drain & terminate Blue (graceful connection drain)
      Phase D: Deploy honeypot at old address (reuse Phase 2)
    """

    def __init__(self, docker_client=None, os_client=None):
        if docker_client:
            self.docker = docker_client
        elif DOCKER_AVAILABLE:
            try:
                self.docker = docker.from_env()
                self.docker.ping()
            except docker.errors.DockerException as exc:
                logger.error(f"âŒ Docker unavailable: {exc}")
                self.docker = None
        else:
            self.docker = None

        self.os_client = os_client or get_opensearch_client()
        self.active_migrations: Dict[str, dict] = {}

    # â”€â”€â”€ Main Migration Flow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def execute_migration(
        self,
        target_container_name: str,
        trigger_reason: str,
        migration_id: Optional[str] = None,
        approved_by: str = "system",
    ) -> dict:
        """
        Execute a full Blue/Green migration for the target container.

        Parameters
        ----------
        target_container_name : str
            Name of the Blue (current) container to migrate.
        trigger_reason : str
            Why the migration was triggered (for audit).
        migration_id : str, optional
            Pre-assigned ID. Generated if not provided.
        approved_by : str
            Analyst who approved this action.

        Returns
        -------
        dict
            Migration result record.
        """
        migration_id = migration_id or str(uuid.uuid4())
        result = {
            "migration_id": migration_id,
            "target_container": target_container_name,
            "status": "INITIATED",
            "trigger_reason": trigger_reason,
            "approved_by": approved_by,
            "started_at": datetime.utcnow().isoformat(),
        }

        if not self.docker:
            logger.info(
                f"ðŸœï¸  DRY-RUN migration: {target_container_name} "
                f"(reason: {trigger_reason})"
            )
            result["status"] = "DRY_RUN"
            self._index_audit(result)
            return result

        try:
            # â”€â”€â”€ Find Blue container â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            try:
                blue = self.docker.containers.get(target_container_name)
            except docker.errors.NotFound:
                logger.error(
                    f"âŒ Target container not found: {target_container_name}"
                )
                result["status"] = "FAILED"
                result["error"] = "Container not found"
                self._index_audit(result)
                return result

            # â”€â”€â”€ Capture rollback snapshot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            snapshot = _capture_rollback_snapshot(blue)
            result["rollback_snapshot"] = snapshot
            result["can_rollback_until"] = (
                datetime.utcnow() + timedelta(hours=ROLLBACK_WINDOW_HOURS)
            ).isoformat()

            logger.info(
                f"ðŸ”„ [{migration_id[:8]}] Starting Blue/Green migration "
                f"for {target_container_name}"
            )

            # â•â•â• Phase A: Spin up Green â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            green_network = create_green_network(self.docker, migration_id)
            green_container = self._create_green_replica(
                blue, green_network, migration_id,
            )

            if not green_container:
                result["status"] = "FAILED"
                result["error"] = "Green container creation failed"
                self._cleanup_green(None, green_network, migration_id)
                self._index_audit(result)
                return result

            # â”€â”€â”€ Health check gate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            healthy = self._wait_for_health(green_container)
            if not healthy:
                logger.error(
                    f"âŒ [{migration_id[:8]}] Green container failed health check"
                )
                result["status"] = "FAILED"
                result["error"] = "Health check timeout"
                self._cleanup_green(green_container, green_network, migration_id)
                self._index_audit(result)
                return result

            result["green_container_id"] = green_container.id
            result["green_network"] = green_network.name

            # â•â•â• Phase B: Switch traffic â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            green_ip = self._get_container_ip(green_container, green_network.name)
            result["green_ip"] = green_ip

            # Connect Green to production network for Nginx to reach it
            try:
                prod_net = self.docker.networks.get(PRODUCTION_NETWORK)
                prod_net.connect(green_container)
                logger.info(
                    f"ðŸ”— [{migration_id[:8]}] Green connected to "
                    f"{PRODUCTION_NETWORK}"
                )
            except docker.errors.NotFound:
                logger.warning(
                    f"âš ï¸  Production network not found, skipping connect"
                )
            except docker.errors.APIError as exc:
                logger.warning(f"âš ï¸  Could not connect Green to production: {exc}")

            # Note: In production, this would update the Nginx upstream config.
            # The MTD Controller handles the Nginx upstream update externally.
            result["traffic_switched_at"] = datetime.utcnow().isoformat()

            logger.info(
                f"âœ… [{migration_id[:8]}] Phase B: Traffic routed to Green "
                f"({green_ip})"
            )

            # â•â•â• Phase C: Drain & terminate Blue â•â•â•â•â•â•
            logger.info(
                f"â³ [{migration_id[:8]}] Phase C: Draining Blue connections "
                f"({DEFAULT_DRAIN_TIMEOUT}s) â€¦"
            )
            time.sleep(DEFAULT_DRAIN_TIMEOUT)

            try:
                blue.stop(timeout=10)
                blue.remove(force=True)
                logger.info(
                    f"ðŸ—‘ï¸  [{migration_id[:8]}] Blue container terminated: "
                    f"{target_container_name}"
                )
            except docker.errors.APIError as exc:
                logger.error(f"âŒ Error removing Blue: {exc}")

            # Rename Green to original name
            try:
                green_container.rename(target_container_name)
                logger.info(
                    f"ðŸ“› [{migration_id[:8]}] Green renamed to "
                    f"{target_container_name}"
                )
            except docker.errors.APIError as exc:
                logger.warning(f"âš ï¸  Could not rename Green: {exc}")

            # â•â•â• Phase D: Deploy honeypot at old address â•
            old_ip = snapshot.get("network_ip_map", {}).get(
                PRODUCTION_NETWORK, ""
            )
            if old_ip:
                self._deploy_honeypot_at_old_address(
                    old_ip, target_container_name, migration_id, snapshot,
                )

            # â”€â”€â”€ Finalize â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            result["status"] = "COMPLETED"
            result["completed_at"] = datetime.utcnow().isoformat()
            self.active_migrations[migration_id] = result
            self._index_audit(result)
            self._index_mutation(result)

            logger.info(
                f"âœ… [{migration_id[:8]}] Migration COMPLETE:\n"
                f"   Blue:  {target_container_name} â†’ TERMINATED\n"
                f"   Green: {green_container.short_id} â†’ ACTIVE ({green_ip})\n"
                f"   Trap:  Honeypot deployed at old IP ({old_ip})\n"
                f"   Rollback available until: {result['can_rollback_until']}"
            )

            return result

        except docker.errors.DockerException as exc:
            logger.error(f"âŒ Docker error during migration: {exc}")
            result["status"] = "FAILED"
            result["error"] = str(exc)
            self._index_audit(result)
            return result
        except Exception as exc:
            logger.error(
                f"âŒ Unexpected migration error: {exc}", exc_info=True,
            )
            result["status"] = "FAILED"
            result["error"] = str(exc)
            self._index_audit(result)
            return result

    # â”€â”€â”€ Green Replica Creation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _create_green_replica(
        self,
        blue: "docker.models.containers.Container",
        green_network: "docker.models.networks.Network",
        migration_id: str,
    ) -> Optional["docker.models.containers.Container"]:
        """
        Create a Green replica with the same image, env, volumes
        but on a different network.
        """
        attrs = blue.attrs
        config = attrs.get("Config", {})
        host_config = attrs.get("HostConfig", {})
        image = config.get("Image", "")

        # Extract image tag properly
        try:
            image_tags = blue.image.tags
            image = image_tags[0] if image_tags else image
        except Exception:
            pass

        short_id = migration_id[:8]
        green_name = f"mtd-green-{blue.name}-{short_id}"

        try:
            green = self.docker.containers.run(
                image=image,
                name=green_name,
                detach=True,
                network=green_network.name,
                environment=config.get("Env", []),
                volumes=host_config.get("Binds", []) or [],
                labels={
                    "neovigil.role": "mtd-green",
                    "neovigil.original": blue.name,
                    "neovigil.migration_id": migration_id,
                    "neovigil.created": datetime.utcnow().isoformat(),
                    **{k: v for k, v in config.get("Labels", {}).items()
                       if not k.startswith("neovigil.role")},
                },
                mem_limit=host_config.get("Memory") or "512m",
                cpu_quota=host_config.get("CpuQuota") or 50000,
                restart_policy={"Name": "no"},
            )

            logger.info(
                f"ðŸŸ¢ [{short_id}] Green container created: "
                f"{green.short_id} ({image})"
            )
            return green

        except docker.errors.ImageNotFound as exc:
            logger.error(f"âŒ Image not found for Green: {image} â€” {exc}")
            return None
        except docker.errors.APIError as exc:
            logger.error(f"âŒ Docker API error creating Green: {exc}")
            return None

    # â”€â”€â”€ Health Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _wait_for_health(
        self,
        container: "docker.models.containers.Container",
        timeout: int = DEFAULT_HEALTH_TIMEOUT,
    ) -> bool:
        """
        Wait for the Green container to become healthy.
        Falls back to checking container status if no healthcheck
        is defined.
        """
        start = time.time()
        check_interval = 3

        while (time.time() - start) < timeout:
            try:
                container.reload()
                status = container.status
                health = container.attrs.get("State", {}).get("Health", {})

                if health:
                    health_status = health.get("Status")
                    if health_status == "healthy":
                        logger.info(
                            f"âœ… Green health check: HEALTHY "
                            f"({time.time() - start:.0f}s)"
                        )
                        return True
                    elif health_status == "unhealthy":
                        logger.error("âŒ Green health check: UNHEALTHY")
                        return False
                else:
                    # No healthcheck defined â€” check if container is running
                    if status == "running":
                        # Give it a quick settling time
                        time.sleep(5)
                        container.reload()
                        if container.status == "running":
                            logger.info(
                                f"âœ… Green is running (no healthcheck, "
                                f"settled after {time.time() - start:.0f}s)"
                            )
                            return True

            except docker.errors.APIError:
                pass

            time.sleep(check_interval)

        logger.error(
            f"âŒ Green health check timed out after {timeout}s"
        )
        return False

    # â”€â”€â”€ Utility â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def _get_container_ip(
        container: "docker.models.containers.Container",
        network_name: str,
    ) -> str:
        """Get the container's IP on a specific network."""
        try:
            container.reload()
            networks = container.attrs.get(
                "NetworkSettings", {}
            ).get("Networks", {})
            net_info = networks.get(network_name, {})
            return net_info.get("IPAddress", "unknown")
        except Exception:
            return "unknown"

    # â”€â”€â”€ Cleanup on Failure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _cleanup_green(self, green_container, green_network, migration_id):
        """Clean up Green resources if migration fails."""
        short_id = migration_id[:8]
        if green_container:
            try:
                green_container.stop(timeout=5)
                green_container.remove(force=True)
                logger.info(f"ðŸ—‘ï¸  [{short_id}] Green container cleaned up")
            except Exception:
                pass
        if green_network:
            try:
                green_network.remove()
                logger.info(f"ðŸ—‘ï¸  [{short_id}] Green network cleaned up")
            except Exception:
                pass

    # â”€â”€â”€ Post-Migration Honeypot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _deploy_honeypot_at_old_address(
        self,
        old_ip: str,
        service_name: str,
        migration_id: str,
        snapshot: dict,
    ):
        """
        After migration, deploy a Phase 2 honeypot at the old IP
        to catch the attacker mid-stride.
        """
        try:
            connection = pika.BlockingConnection(
                pika.ConnectionParameters(
                    host=RABBITMQ_HOST,
                    connection_attempts=2,
                    retry_delay=1,
                )
            )
            channel = connection.channel()
            channel.queue_declare(queue=DECOY_DEPLOY_QUEUE, durable=True)

            deploy_payload = {
                "prediction_id": f"mtd-trap-{migration_id[:8]}",
                "tenant_id": "default",
                "risk_score": 100,          # Max priority trap
                "kill_chain": [{
                    "step": 1,
                    "tactic": "Lateral Movement",
                    "technique_id": "T1021",
                    "target_host": service_name,
                    "target_ip": old_ip,
                    "target_port": _extract_primary_port(snapshot),
                    "confidence": 1.0,
                }],
                "source": "mtd_migration",
                "migration_id": migration_id,
                "timestamp": datetime.utcnow().isoformat(),
            }
            channel.basic_publish(
                exchange="",
                routing_key=DECOY_DEPLOY_QUEUE,
                body=json.dumps(deploy_payload),
                properties=pika.BasicProperties(delivery_mode=2),
            )
            connection.close()

            logger.info(
                f"ðŸ¯ [{migration_id[:8]}] Honeypot deploy task sent "
                f"for old address {old_ip}"
            )
        except Exception as exc:
            logger.warning(
                f"âš ï¸  Failed to deploy post-migration honeypot: {exc}"
            )

    # â”€â”€â”€ Rollback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def execute_rollback(
        self,
        migration_id: str,
        rolled_back_by: str = "system",
    ) -> dict:
        """
        Rollback a completed migration by restoring the original
        container from its snapshot.
        """
        result = {
            "rollback_id": f"rb-{uuid.uuid4().hex[:8]}",
            "migration_id": migration_id,
            "status": "INITIATED",
            "rolled_back_by": rolled_back_by,
            "started_at": datetime.utcnow().isoformat(),
        }

        migration = self.active_migrations.get(migration_id)
        if not migration:
            # Try to fetch from OpenSearch
            migration = self._fetch_migration_record(migration_id)

        if not migration:
            result["status"] = "FAILED"
            result["error"] = "Migration record not found"
            self._index_audit(result)
            return result

        # Check rollback window
        rollback_until = migration.get("can_rollback_until", "")
        if rollback_until:
            try:
                deadline = datetime.fromisoformat(rollback_until)
                if datetime.utcnow() > deadline:
                    result["status"] = "FAILED"
                    result["error"] = "Rollback window expired"
                    self._index_audit(result)
                    return result
            except ValueError:
                pass

        if not self.docker:
            result["status"] = "DRY_RUN"
            self._index_audit(result)
            return result

        snapshot = migration.get("rollback_snapshot", {})
        if not snapshot:
            result["status"] = "FAILED"
            result["error"] = "No rollback snapshot available"
            self._index_audit(result)
            return result

        try:
            original_name = snapshot.get("container_name", "")
            image = snapshot.get("image", "")

            # Stop current (Green-turned-primary) if it exists
            try:
                current = self.docker.containers.get(original_name)
                current.stop(timeout=10)
                current.remove(force=True)
                logger.info(f"ðŸ—‘ï¸  Removed current container: {original_name}")
            except docker.errors.NotFound:
                pass

            # Recreate original
            restored = self.docker.containers.run(
                image=image,
                name=original_name,
                detach=True,
                environment=snapshot.get("env_vars", []),
                volumes=snapshot.get("volumes", []) or [],
                labels=snapshot.get("labels", {}),
                mem_limit=snapshot.get("memory_limit") or "512m",
                cpu_quota=snapshot.get("cpu_quota") or 50000,
                restart_policy=snapshot.get("restart_policy", {"Name": "no"}),
            )

            # Connect to original networks
            for net_name in snapshot.get("networks", []):
                try:
                    net = self.docker.networks.get(net_name)
                    net.connect(restored)
                except Exception:
                    pass

            result["status"] = "COMPLETED"
            result["restored_container_id"] = restored.id
            result["completed_at"] = datetime.utcnow().isoformat()

            logger.info(
                f"âœ… Rollback complete for migration {migration_id[:8]}: "
                f"restored {original_name}"
            )

        except Exception as exc:
            result["status"] = "FAILED"
            result["error"] = str(exc)
            logger.error(f"âŒ Rollback failed: {exc}")

        self._index_audit(result)
        return result

    # â”€â”€â”€ OpenSearch â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _fetch_migration_record(self, migration_id: str) -> Optional[dict]:
        """Fetch a migration record from OpenSearch."""
        try:
            resp = self.os_client.get(
                index=MTD_AUDIT_INDEX, id=migration_id,
            )
            return resp.get("_source")
        except Exception:
            return None

    def _index_audit(self, record: dict):
        """Index an audit record to mtd-audit-log."""
        doc_id = record.get("migration_id") or record.get("rollback_id", "")
        try:
            self.os_client.index(
                index=MTD_AUDIT_INDEX,
                id=doc_id,
                body=record,
                refresh=True,
            )
        except Exception as exc:
            logger.error(f"âŒ Audit indexing failed: {exc}")

    def _index_mutation(self, record: dict):
        """Index active migration to mtd-active-mutations."""
        try:
            doc = {
                **record,
                "mutation_type": "migration",
            }
            self.os_client.index(
                index=MTD_MUTATIONS_INDEX,
                id=record["migration_id"],
                body=doc,
                refresh=True,
            )
        except Exception as exc:
            logger.error(f"âŒ Mutation indexing failed: {exc}")


# â”€â”€â”€ Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _extract_primary_port(snapshot: dict) -> int:
    """Extract the primary port from a rollback snapshot."""
    ports = snapshot.get("ports", {})
    if ports:
        first_port = next(iter(ports), "")
        try:
            return int(first_port.split("/")[0])
        except (ValueError, IndexError):
            pass
    return 22  # Default SSH fallback
