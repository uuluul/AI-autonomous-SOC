import os
import time
import json
import uuid
import logging
import glob
import pika
import requests
from datetime import datetime, timedelta
from llm_client import LLMClient, LocalLLMCriticalError
from to_stix import build_stix_bundle
from to_pdf import generate_pdf_report
from extract_schema import DEFAULT_SYSTEM_PROMPT, EXTRACTION_SCHEMA_DESCRIPTION
from validate_stix import validate_stix_json
from utils import chunk_text, merge_extractions
from database import insert_task
from pii_masker import PIIMasker
from src.setup_opensearch import upsert_indicator, upload_to_opensearch as upload_to_os_lib, get_opensearch_client
from src.enrichment import EnrichmentEngine
from src.cve_enrichment import CVEEnricher
import schedule
import threading
import subprocess
import ipaddress
from src.audit_logger import AuditLogger

logging.basicConfig(level=logging.INFO, format='%(asctime)s - [%(levelname)s] - %(message)s')
logger = logging.getLogger(__name__)

# ç’°å¢ƒè®Šæ•¸
RABBITMQ_HOST = os.getenv("RABBITMQ_HOST", "rabbitmq")
RABBITMQ_QUEUE = "cti_queue"
ROLE = os.getenv("ROLE", "master")  # 'master' or 'worker'

# è³‡æ–™å¤¾è¨­å®š
INPUT_DIR = "data/input"
PROCESSED_DIR = "data/processed"
OUTPUT_DIR = "out"

# OpenSearch è¨­å®š (ç”¨æ–¼ RAG æª¢ç´¢)
OS_HOST = os.getenv("OPENSEARCH_HOST", "opensearch-node")
OS_PORT = os.getenv("OPENSEARCH_PORT", "9200")
OS_USER = os.getenv("OPENSEARCH_USER", "admin")
OS_PASS = os.getenv("OPENSEARCH_PASSWORD", "admin")
OS_AUTH = (OS_USER, OS_PASS)
BASE_URL = f"http://{OS_HOST}:{OS_PORT}"
INDEX_KB = "cti-reports"

# Enterprise Guardrails: Critical Subnets
CRITICAL_SUBNETS = [
    ipaddress.ip_network("10.0.0.0/8"),
    ipaddress.ip_network("192.168.0.0/16"),
    ipaddress.ip_network("172.16.0.0/12"),
    ipaddress.ip_network("127.0.0.0/8")
]

def is_critical_infrastructure(ip_str):
    """Check if IP belongs to critical internal infrastructure"""
    try:
        ip = ipaddress.ip_address(ip_str)
        for subnet in CRITICAL_SUBNETS:
            if ip in subnet:
                return True
    except:
        return False
    return False

def ensure_dirs():
    """ç¢ºä¿å¿…è¦çš„è³‡æ–™å¤¾å­˜åœ¨"""
    for d in [INPUT_DIR, PROCESSED_DIR, OUTPUT_DIR]:
        os.makedirs(d, exist_ok=True)

# --- RabbitMQ é€£ç·š Helper ---
def get_rabbitmq_connection():
    """å»ºç«‹ RabbitMQ é€£ç·šèˆ‡ Channel"""
    credentials = pika.PlainCredentials('user', 'password')
    parameters = pika.ConnectionParameters(RABBITMQ_HOST, 5672, '/', credentials, heartbeat=600)
    
    while True:
        try:
            connection = pika.BlockingConnection(parameters)
            channel = connection.channel()
            channel.queue_declare(queue=RABBITMQ_QUEUE, durable=True)
            return connection, channel
        except pika.exceptions.AMQPConnectionError:
            logger.warning("  Waiting for RabbitMQ...")
            time.sleep(5)

# --- RAG æª¢ç´¢å‡½å¼ ---
def retrieve_context(text_content: str, top_k: int = 3) -> str:
    """
    RAG æ ¸å¿ƒï¼šåŒæ™‚æŸ¥è©¢ã€Œå¤–éƒ¨å°ˆå®¶çŸ¥è­˜ (MITRE/AI Defense)ã€èˆ‡ã€Œå…§éƒ¨æ­·å²æ¡ˆä¾‹ (Reports)ã€
    """
    if not text_content: 
        return ""
    
    client = get_opensearch_client()
    context_parts = []
    
    # æœå°‹å…§å®¹æˆªæ–·ï¼Œé¿å… Token éé•·
    search_query = text_content[:1000]

    # =========================================================
    # æŸ¥è©¢ cti-knowledge-base (å¤–éƒ¨çŸ¥è­˜)
    # ç›®çš„ï¼šæ‰¾å‡ºé€™æ®µæ–‡å­—æ¶‰åŠä»€éº¼æ”»æ“Šæ‰‹æ³•æˆ–é˜²ç¦¦å»ºè­°
    # =========================================================
    try:
        kb_response = client.search(
            index="cti-knowledge-base",
            body={
                "size": top_k,
                "query": {
                    "multi_match": {
                        "query": search_query,
                        # æ¨™é¡Œ (name) æ¬Šé‡ x3ï¼Œæè¿° (description) æ¬Šé‡ x1
                        "fields": ["name^3", "description"], 
                        "type": "best_fields"
                    }
                }
            }
        )
        
        hits = kb_response.get("hits", {}).get("hits", [])
        if hits:
            attacks = []
            defenses = []
            
            for hit in hits:
                src = hit["_source"]
                # æ ¼å¼ï¼š[ä¾†æº] ID åç¨±: æè¿°ç‰‡æ®µ
                info = f"- [{src.get('source', 'UNK').upper()}] {src.get('name', '')} ({src.get('external_id', 'N/A')}): {src.get('description', '')[:200]}..."
                
                if src.get("type") == "defense":
                    defenses.append(info)
                else:
                    attacks.append(info)
            
            # çµ„è£çŸ¥è­˜åº« Context
            if attacks:
                context_parts.append("  [Known Attack Patterns (MITRE ATT&CK)]:")
                context_parts.extend(attacks)
            if defenses:
                context_parts.append("  [Recommended Defenses (AI Defense)]:")
                context_parts.extend(defenses)
                
    except Exception as e:
        logger.warning(f"  Knowledge Base search failed: {e}")

    # =========================================================
    # æŸ¥è©¢ cti-reports (å…§éƒ¨æ­·å²)
    # ç›®çš„ï¼šæ‰¾å‡ºä»¥å‰é‡éé€™ä»¶äº‹å—ï¼Ÿ
    # =========================================================
    try:
        report_response = client.search(
            index="cti-reports",
            body={
                "size": top_k,
                "query": {
                    "more_like_this": {
                        # åœ¨é€™äº›æ¬„ä½ä¸­å°‹æ‰¾ç›¸ä¼¼å…§å®¹
                        "fields": ["content", "analysis_summary", "log_text"],
                        "like": search_query,
                        "min_term_freq": 1,
                        "max_query_terms": 12
                    }
                }
            }
        )
        
        hits = report_response.get("hits", {}).get("hits", [])
        if hits:
            history = []
            for hit in hits:
                src = hit["_source"]
                # æ’é™¤è‡ªå·± (å¦‚æœæ˜¯é‡è·‘çš„è©±)
                if src.get("content") == text_content: continue
                
                # æ ¼å¼ï¼šæ—¥æœŸ | æª”å | æ‘˜è¦
                info = f"- {src.get('timestamp', 'Unknown Date')[:10]} | {src.get('filename', 'Unknown')}: {src.get('analysis_summary', 'No summary')[:150]}..."
                history.append(info)
            
            if history:
                context_parts.append("\n  [Similar Past Internal Incidents]:")
                context_parts.extend(history)

    except Exception as e:
        logger.warning(f"  Historical Report search failed: {e}")

    # =========================================================
    # æŸ¥è©¢ ai-feedback (äººé¡åé¥‹é–‰ç’°)
    # ç›®çš„ï¼šæ‰¾å‡º AI æ›¾ç¶“çš„èª¤åˆ¤ï¼Œé¿å…é‡è¹ˆè¦†è½
    # =========================================================
    try:
        feedback_response = client.search(
            index="ai-feedback",
            body={
                "size": top_k,
                "query": {
                    "more_like_this": {
                        "fields": ["content", "reason"],
                        "like": search_query,
                        "min_term_freq": 1,
                        "max_query_terms": 12
                    }
                }
            }
        )
        
        hits = feedback_response.get("hits", {}).get("hits", [])
        if hits:
            mistakes = []
            for hit in hits:
                src = hit["_source"]
                # æ ¼å¼ï¼š[REJECTED] åŸå› : åŸæ–‡ç‰‡æ®µ
                info = f"- [REJECTED MISTAKE] Reason: {src.get('reason', 'No reason')} | Original Text: {src.get('content', '')[:150]}..."
                mistakes.append(info)
            
            if mistakes:
                context_parts.append("\n  [  Human Feedback / Past Mistakes - DO NOT REPEAT THESE ERRORS]:")
                context_parts.extend(mistakes)

    except Exception as e:
        logger.warning(f"  AI Feedback search failed: {e}")

    # =========================================================
    # å›å‚³æœ€çµ‚çµ„åˆæ–‡å­—
    # =========================================================
    if not context_parts:
        return ""
        
    return "\n".join(context_parts)


# ================= è‡ªå‹•æ¸…ç†èˆŠæª”æ¡ˆé‚è¼¯ =================
def cleanup_old_files():
    """
    å®šæœŸä»»å‹™ï¼šåˆªé™¤ processed è³‡æ–™å¤¾ä¸­è¶…é RETENTION_DAYS çš„èˆŠæª”æ¡ˆ
    """
    RETENTION_DAYS = 30  #  è¨­å®šä¿ç•™å¹¾å¤©
    cutoff_time = time.time() - (RETENTION_DAYS * 86400) # è¨ˆç®—æˆªæ­¢æ™‚é–“æˆ³
    
    logger.info(f"ğŸ§¹ [Cleanup] Starting cleanup of files older than {RETENTION_DAYS} days...")
    
    deleted_count = 0
    try:
        # æƒæ processed è³‡æ–™å¤¾
        for filename in os.listdir(PROCESSED_DIR):
            file_path = os.path.join(PROCESSED_DIR, filename)
            
            # åªè™•ç†æª”æ¡ˆï¼Œä¸è™•ç†è³‡æ–™å¤¾
            if os.path.isfile(file_path):
                file_mtime = os.path.getmtime(file_path)
                
                # å¦‚æœæª”æ¡ˆä¿®æ”¹æ™‚é–“æ—©æ–¼æˆªæ­¢æ™‚é–“ï¼Œå°±åˆªé™¤
                if file_mtime < cutoff_time:
                    try:
                        os.remove(file_path)
                        deleted_count += 1
                    except OSError as e:
                        logger.error(f"  Failed to delete {filename}: {e}")
                        
        if deleted_count > 0:
            logger.info(f"  [Cleanup] Deleted {deleted_count} old files.")
        else:
            logger.info("  [Cleanup] No files needed deletion.")
            
    except Exception as e:
        logger.error(f"  [Cleanup] Error during cleanup: {e}")

# ================= è‡ªå‹•æ›´æ–°æ’ç¨‹ =================

def update_knowledge_base_job():
    """
    å®šæœŸä»»å‹™ï¼šåŸ·è¡Œ setup_knowledge_base.py ä»¥æ›´æ–° MITRE / AI Defense è³‡æ–™
    """
    logger.info("  [CronJob] Starting scheduled Knowledge Base update (AI Defense/MITRE)...")
    try:
        # å‘¼å«å¦å¤–ä¸€æ”¯ Python è…³æœ¬ä¾†åŸ·è¡Œä¸‹è¼‰èˆ‡æ›´æ–°
        result = subprocess.run(
            ["python", "/app/src/setup_knowledge_base.py"], 
            capture_output=True, 
            text=True
        )
        
        if result.returncode == 0:
            logger.info("  [CronJob] Knowledge Base updated successfully.")
            # logger.info(result.stdout) # å¦‚æœè¦çœ‹è©³ç´°è¼¸å‡ºå¯ä»¥å–æ¶ˆè¨»è§£
        else:
            logger.error(f"  [CronJob] Update script failed:\n{result.stderr}")
            
    except Exception as e:
        logger.error(f"  [CronJob] Execution error: {e}")

def run_scheduler_thread():
    """èƒŒæ™¯æ’ç¨‹åŸ·è¡Œç·’"""
    logger.info("  Scheduler initialized. AI Defense will update periodically.")
    
    # è¨­å®šæ’ç¨‹ï¼šé è¨­ æ¯ 12 å°æ™‚æ›´æ–°ä¸€æ¬¡
    schedule.every(12).hours.do(update_knowledge_base_job)
    # æ¯å¤©å‡Œæ™¨ 03:00 åŸ·è¡Œç¡¬ç¢Ÿå¤§æƒé™¤
    schedule.every().day.at("03:00").do(cleanup_old_files)

    # å•Ÿå‹•æ™‚å…ˆç«‹å³è·‘ä¸€æ¬¡ï¼Œç¢ºä¿è³‡æ–™åº«æœ‰æœ€æ–°è³‡æ–™
    update_knowledge_base_job()

    while True:
        schedule.run_pending()
        time.sleep(60) # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰ä»»å‹™è¦è·‘

# ============================================================

def move_to_processed(file_path, filename):
    """å°‡è™•ç†å®Œçš„æª”æ¡ˆç§»è‡³ processed è³‡æ–™å¤¾"""
    # ç”¢ç”Ÿæ™‚é–“æˆ³è¨˜ï¼Œé¿å…æª”åé‡è¤‡
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    processed_dest = os.path.join(PROCESSED_DIR, f"{timestamp}_{filename}")
    
    try:
        if os.path.exists(file_path):
            os.rename(file_path, processed_dest)
            logger.info(f"  File archived to: {processed_dest}")
        else:
            logger.warning(f"  File not found during archive: {file_path}")
    except OSError as e:
        logger.error(f"  Error archiving file: {e}")


def process_task(task_payload: dict, llm: LLMClient, enricher: EnrichmentEngine, cve_enricher: CVEEnricher, audit_logger: AuditLogger):
    """
    Worker é‚è¼¯ï¼šæ”¯æ´ã€Œæª”æ¡ˆæ¨¡å¼ã€èˆ‡ã€Œä¸²æµæ¨¡å¼ã€çš„é€šç”¨è™•ç†å™¨
    Payload æ ¼å¼ç¯„ä¾‹ï¼š
      1. æª”æ¡ˆ: {"file_path": "/app/data/input/LOG.txt", "filename": "LOG.txt"}
      2. ä¸²æµ: {"timestamp": "...", "source_ip": "...", "message": "..."}
    """
    
    # --- åˆ¤æ–·ä¾†æºä¸¦å–å¾—å…§å®¹ ---
    file_path = None
    raw_content = None

    # ========== ğŸ†• RAW MODE (E2E / API ingestion) ==========
    if "raw_log" in task_payload or "message" in task_payload:
        raw_content = task_payload.get("raw_log") or task_payload.get("message")
        filename = task_payload.get("filename") or f"RAW_{task_payload.get('event_id', uuid.uuid4())}.log"

        logger.info(f"  [Raw Mode] Processing: {filename} (event_id={task_payload.get('event_id')})")

    # ========== ğŸ“‚ FILE MODE ==========
    elif "file_path" in task_payload:
        filename = task_payload.get("filename", "unknown.txt")
        file_path = task_payload["file_path"]

        logger.info(f"  [File Mode] Processing: {filename}")

        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                raw_content = f.read()
        except Exception as e:
            logger.error(f"  Failed to read file: {e}")
            return

    # ========== âš¡ STREAM MODE ==========
    else:
        logger.info(f"âš¡ [Stream Mode] Processing live log event")

        ts = int(time.time())
        src_ip = task_payload.get("source_ip", "unknown_ip")
        filename = f"LOG_STREAM_{ts}_{src_ip}"

        raw_content = json.dumps(task_payload, ensure_ascii=False)

    # ================= PII é®ç½© (éš±ç§ä¿è­·) =================
    masker = PIIMasker()
    safe_content = masker.mask(raw_content) 
    
    if safe_content != raw_content:
        logger.info("  PII Masking applied (Emails/Phones redacted).")

    is_log = filename.startswith("LOG_")
    normalized_data = {} # å­˜æ”¾çµæ§‹åŒ–è³‡æ–™

    # ================ AI è‡ªé©æ‡‰æ­£è¦åŒ–  =================
    if is_log:
        try:
            # å˜—è©¦ç›´æ¥è§£æ (å¦‚æœ Fluent Bit å·²ç¶“é€ä¾† JSONï¼Œé€™è£¡æœƒæˆåŠŸ)
            normalized_data = json.loads(safe_content)
            logger.info(f"  {filename} is valid JSON. Using natively.")
        except json.JSONDecodeError:
            # åŠ å…¥è¼•é‡ç´šå¿«ç¯© (Optimization 3)
            suspicious_keywords = ["failed", "error", "drop", "deny", "alert", "attack", "unauthorized", "sql", "cve", "exploited"]
            if not any(k in safe_content.lower() for k in suspicious_keywords):
                logger.info(f"  [Triage] Log looks completely normal. Skipping AI to save cost.")
                return # ç›´æ¥ç•¥éæ­£å¸¸ Log

            # å¦‚æœæ˜¯ Raw Textï¼Œå‘¼å« AI é€²è¡Œæ­£è¦åŒ–
            logger.info(f"  {filename} is raw text. Starting AI Adaptive Normalization...")
            normalized_data = llm.normalize_log(safe_content)
            
            if not normalized_data:
                normalized_data = {}
            
            # æ›´æ–° safe_content ç‚ºæ¨™æº–åŒ–å¾Œçš„ JSON å­—ä¸²
            safe_content = json.dumps(normalized_data, ensure_ascii=False)
            logger.info(f"  AI Normalized Data: {safe_content}")

    # ================= é•·æ–‡æœ¬åˆ‡ç‰‡èˆ‡ AI åˆ†æ =================
    chunks = chunk_text(safe_content)
    if len(chunks) > 1:
        logger.info(f"  Large document detected! Split into {len(chunks)} chunks.")

    chunk_results = []
    has_rag_context = False

    for i, chunk in enumerate(chunks):
        # RAG: åŒæ™‚æŸ¥è©¢çŸ¥è­˜åº«èˆ‡æ­·å²å ±å‘Š
        rag_context = retrieve_context(chunk)
        if rag_context:
            has_rag_context = True

        enhanced_chunk = f"{rag_context}\n\n[Report Segment {i+1}]:\n{chunk}"

        try:
            chunk_extraction = llm.get_extraction(enhanced_chunk)
            if chunk_extraction:
                # Capture RAG Context for Explainable AI (XAI)
                if rag_context:
                    chunk_extraction["rag_context"] = rag_context
                
                chunk_results.append(chunk_extraction)
        except Exception as e:
            logger.error(f"  Error analyzing chunk {i+1}: {e}")
            continue

    # ================= åˆä½µåˆ†æçµæœ =================
    if not chunk_results:
        logger.warning("  LLM returned empty result for all chunks.")
        if file_path: move_to_processed(file_path, filename)
        return

    extracted = merge_extractions(chunk_results)

    # === Multi-Tenancy Injection ===
    tenant_id = task_payload.get("tenant_id", "default_tenant")
    extracted["tenant_id"] = tenant_id
    logger.info(f"  [Multi-Tenancy] Processing for Tenant: {tenant_id}")

    # åˆä½µæ­£è¦åŒ–è³‡æ–™ (è£œé½Š IP ç­‰æ¬„ä½)
    if is_log and normalized_data:
        if "source_ip" in normalized_data:
            if "indicators" not in extracted: extracted["indicators"] = {}
            if "ipv4" not in extracted["indicators"]: extracted["indicators"]["ipv4"] = []
            
            ip = normalized_data["source_ip"]
            if ip and ip not in extracted["indicators"]["ipv4"]:
                extracted["indicators"]["ipv4"].append(ip)
        
        extracted.update(normalized_data)

    logger.info(f"  Analysis Complete. Merged {len(chunk_results)} chunks.")

    # çµ±ä¸€æ¬„ä½åç¨±
    if "confidence" not in extracted and "confidence_score" in extracted:
        extracted["confidence"] = extracted["confidence_score"]

    # é—œéµå­—å¼·åˆ¶è£œåˆ†
    current_score = extracted.get("confidence", 0)
    critical_keywords = [
        "CRITICAL", "RANSOMWARE", "MALWARE", "ATTACK", "BLOCKED", "CISA", 
        "JNDI", "EXPLOIT", "UNAUTHORIZED", "DENIED", "FAILED LOGIN", "ROOT", "SQL INJECTION"
    ]    
    if current_score < 50:
        content_upper = safe_content.upper()
        if any(k in content_upper for k in critical_keywords):
            logger.warning(f"  LLM gave low score ({current_score}), but found CRITICAL keywords. Overriding to 95!")
            extracted["confidence"] = 95
    
    if extracted.get("confidence") is None:
        extracted["confidence"] = 0

    # === Compatibility Fields (Test & Legacy Support) ===
    extracted["ai_confidence"] = extracted["confidence"]
    extracted["mitre_ttps"] = extracted.get("ttps", [])
    
    if extracted["confidence"] >= 80:
        extracted["risk_level"] = "High"
    elif extracted["confidence"] >= 50:
        extracted["risk_level"] = "Medium"
    else:
        extracted["risk_level"] = "Low"

    # ================= è±å¯ŒåŒ– (Enrichment & Hybrid Detection) =================
    try:
        enriched_data = {}
        ti_results = {}
        indicators = extracted.get("indicators", {})
        
        max_ti_score = 0
        
        for ip in indicators.get("ipv4", []):
            # 1. Internal/Geo Enrichment
            info = enricher.enrich_ip(ip)
            if info["geo"] or info["asset"]:
                enriched_data[ip] = info
            
            # 2. External Threat Intel (Hybrid)
            if "threat_intel" in info:
                ti = info["threat_intel"]
                ti_results[ip] = ti
                if ti["score"] > max_ti_score:
                    max_ti_score = ti["score"]
                    
        extracted["enrichment"] = enriched_data
        extracted["threat_intel"] = ti_results
        
        # === Hybrid Scoring Logic ===
        # If Threat Intel says it's malicious (Score > 80), override AI Confidence
        current_conf = extracted.get("confidence", 0)
        
        if max_ti_score >= 80:
            logger.warning(f"  Hybrid Detection: Threat Intel High Risk ({max_ti_score}). Boosting Confidence to 95.")
            extracted["confidence"] = 95
            extracted["attack_type"] = "Authorized Threat Intel Match"
            
        elif max_ti_score >= 50 and current_conf < 60:
             logger.info(f"  Hybrid Detection: Threat Intel Suspicious ({max_ti_score}). Boosting Confidence.")
             extracted["confidence"] = 75
             
    except Exception as e:
        logger.error(f"  Enrichment failed: {e}")

    # ================= 1.6 CVE æ¼æ´é—œè¯ =================
    try:
        vulnerability_results = []

        ai_cve_ids = extracted.get("cve_ids", [])
        regex_cve_ids = cve_enricher.extract_cve_ids(raw_content)
        all_cve_ids = list(set(ai_cve_ids + regex_cve_ids))
        
        if all_cve_ids:
            logger.info(f"  Identifed CVEs (AI + Regex): {all_cve_ids}")

        for cid in all_cve_ids:
            if not any(v["id"] == cid for v in vulnerability_results):
                details = cve_enricher.get_cve_details(cid)
                if details:
                    vulnerability_results.append(details)

        extracted["vulnerabilities"] = vulnerability_results
        
        if any(isinstance(v.get("score"), (int, float)) and v.get("score") >= 7.0 for v in vulnerability_results):
            if extracted.get("confidence", 0) < 90:
                extracted["confidence"] = 95
                logger.warning("  Critical Vulnerability Detected! Confidence boosted to 95.")

        # ================= Fallback: General AI Remediation =================
        if not extracted["vulnerabilities"]:
            # If no specific CVE, use the AI's general remediation advice
            # Format: ID="", Severity=Severity, Description=Analysis, Remediation=Steps
            
            general_remediation = extracted.get("remediation", "Isolate affected host and block traffic.")
            
            extracted["vulnerabilities"].append({
                "id": "", # Empty ID as requested
                "cvss": 0.0,
                "score": 0.0,
                "severity": extracted.get("severity", "High"),
                "description": f"AI Behavioral Analysis: {extracted.get('attack_type', 'Suspicious Activity')} detected.\n\nSummary: {extracted.get('summary', 'Traffic pattern matches known attack TTPs.')}",
                "remediation": general_remediation,
                "references": []
            })
            logger.info("  No specific CVE found. Added General AI Remediation analysis.")

    except Exception as e:
        logger.error(f"  CVE Enrichment Failed: {e}")

    # ================= å»ºç«‹ STIX Bundle =================
    stix_bundle = build_stix_bundle(extracted)
    stix_json_str = json.dumps(stix_bundle, indent=4, ensure_ascii=False)
        
    static_out_path = os.path.join(OUTPUT_DIR, "bundle_stix21.json")
    with open(static_out_path, "w", encoding="utf-8") as f:
        f.write(stix_json_str)

    # ================= æ™ºæ…§åˆ†æµè·¯ç”±é‚è¼¯ ===================
    is_log = filename.startswith("LOG_")
    is_rss = filename.startswith("RSS_")
    is_otx = filename.startswith("OTX_CTI_")
    is_abusech = filename.startswith("ABUSECH_CTI_")
    is_github = filename.startswith("GITHUB_CTI_")
    is_premium_feed = is_otx or is_abusech or is_github 
    
    # åˆ¤æ–·æ˜¯å¦ç‚ºæ‰‹å‹•ä¸Šå‚³ (Manual_...)
    is_manual = filename.startswith("Manual_")

    confidence = extracted.get("confidence", 0)
    threat_matched = has_rag_context 

    # å®šç¾©ã€Œæœ‰å¯¦è³ªæŒ‡æ¨™ã€çš„æƒ…å ±
    has_indicators = bool(extracted.get("indicators", {}).get("ipv4") or 
                          extracted.get("indicators", {}).get("domains") or 
                          extracted.get("indicators", {}).get("urls") or 
                          extracted.get("cve_ids"))

    # Logic Split:
    # 1. Knowledge Base Only (Crawlers/Feeds) -> No PDF, No Blocking
    # 2. Actionable Alerts (Manual, High Risk Logs) -> PDF + Blocking

    is_crawler_content = is_rss or is_premium_feed

    # High Risk Definition:
    # 1. Very High Confidence (>= 80%) indicating malicious/virus
    # 2. Valid Threat Match (RAG)
    is_confirmed_high_risk = (confidence >= 80) or threat_matched

    # === GUARDRAIL CHECK ===
    force_human_review = False
    indicators_list = extracted.get("indicators", {}).get("ipv4", [])
    
    if is_confirmed_high_risk:
        for ip in indicators_list:
            if is_critical_infrastructure(ip):
                logger.warning(f"ğŸ›‘ [GUARDRAIL] Target {ip} is CRITICAL INFRASTRUCTURE. Downgrading to MANUAL APPROVAL.")
                
                # Audit Log the intervention
                audit_logger.log_event(
                    actor="SOAR-Guardrail",
                    action="DOWNGRADE_ACTION",
                    target=filename, # Use the local variable 'filename'
                    status="SUCCESS",
                    justification=f"Prevented Auto-Block on Critical IP: {ip}",
                    details={"original_confidence": confidence}
                )
                
                is_confirmed_high_risk = False
                force_human_review = True
                break
        
        # === GUARDRAIL 2: Threat Intel Disagreement (AI Potential Hallucination) ===
        # If AI says High Risk, but Threat Intel explicitly says CLEAN (Score < 20)
        ti_data = extracted.get("threat_intel", {})
        if ti_data and is_confirmed_high_risk:
            # Check if ANY IP has high score. If ALL are low score, then downgrade.
            max_ti = 0
            for ip, info in ti_data.items():
                if info.get("score", 0) > max_ti:
                    max_ti = info.get("score", 0)
            
            if max_ti < 20: 
                 logger.warning(f"ğŸ›‘ [GUARDRAIL] AI High Confidence ({confidence}%) but Threat Intel says CLEAN (Max Score: {max_ti}). Downgrading to MANUAL.")
                 
                 audit_logger.log_event(
                    actor="Hybrid-Guardrail",
                    action="DOWNGRADE_ACTION",
                    target=filename,
                    status="SUCCESS",
                    justification=f"Threat Intel Disagreement (AI: High vs TI: Clean)",
                    details={"ai_confidence": confidence, "ti_score": max_ti}
                )
                 is_confirmed_high_risk = False
                 force_human_review = True

    # 1. ç´”çŸ¥è­˜åº«æ­¸æª” (Crawlers OR Low Risk Manual/Logs)
    # If it's a crawler, or it's a Manual/Log entry that is NOT high risk, index only.
    if (is_crawler_content or not is_confirmed_high_risk) and not force_human_review:
        logger.info(f"  [Knowledge Base] Indexing content: {filename} (Confidence: {confidence}%, HighRisk: {is_confirmed_high_risk})")
        
        # å¯«å…¥ OpenSearch çš„æ–‡ä»¶
        doc = extracted.copy()
        
        if is_rss: src_type = "rss"
        elif is_premium_feed: src_type = "premium_cti_feed"
        elif is_manual: src_type = "manual_low_risk"
        elif is_log: src_type = "log_low_risk"
        else: src_type = "external_feed"

        doc.update({
            "filename": filename,
            "timestamp": datetime.now().isoformat(),
            "expiration_date": (datetime.now() + timedelta(days=90)).isoformat(), # Crawled data kept longer for training
            "pdf_path": None, # No PDF
            "source_type": src_type,
            "threat_matched": threat_matched
        })
        
        report_id = os.path.splitext(filename)[0]
        # Upload to cti-reports (Knowledge Base)
        upload_to_os_lib(doc, report_id, "cti-reports")
        logger.info(f"  Indexed to Knowledge Base (cti-reports). No Report/Block generated.")

    # 2. è§¸ç™¼è­¦å ±èˆ‡é˜»æ“‹ (High Risk Manual or High Risk Logs)
    elif is_confirmed_high_risk and not force_human_review:
        
        # å»ºç«‹ä¼æ¥­ç™½åå–® (Optimization 2)
        WHITELIST_IPS = {"8.8.8.8", "1.1.1.1", "127.0.0.1"} 
        indicators = extracted.get("indicators", {})
        
        # Pre-check: Don't generate report if IP is whitelisted (only for logs)
        if is_log:
            should_skip = False
            for ip in indicators.get("ipv4", []):
                if ip in WHITELIST_IPS or ip.startswith("192.168.") or ip.startswith("10."):
                    logger.info(f"    Log Source {ip} is whitelisted. Skipping Report Generation.")
                    should_skip = True
                    break
            if should_skip:
                return

        trigger_reason = "Confirmed High Risk (Manual/Log)"
        logger.info(f"    Actionable Alert Triggered [{trigger_reason} Confidence:{confidence}%]. Executing Response...")

        # ç”Ÿæˆ PDF
        pdf_filename = f"{os.path.splitext(filename)[0]}.pdf"
        pdf_path = os.path.join("data/reports", pdf_filename)
        generate_pdf_report(extracted, pdf_path)
        
        report_info = {"filename": filename, "confidence": confidence}
        
        for ip in indicators.get("ipv4", []):
            upsert_indicator(ip, "ipv4", report_info)
        for domain in indicators.get("domains", []):
            upsert_indicator(domain, "domain", report_info)

        # AUDIT LOGGING: AI BLOCKING ACTION
        audit_description = f"AI Auto-Blocked {len(indicators.get('ipv4', []))} IPs and {len(indicators.get('domains', []))} Domains. Confidence: {confidence}%"
        audit_logger.log_event(
            actor="AI-Agent",
            action="BLOCK_THREAT",
            target=filename,
            status="SUCCESS",
            justification=f"High Confidence Threat ({confidence}%) matched RAG/Rules.",
            details={"indicators": indicators, "attack_type": extracted.get("attack_type", "Unknown")}
        )

        # Indexing
        doc = extracted.copy()
        src_type = "manual" if is_manual else "suspicious_log"

        doc.update({
            "filename": filename,
            "timestamp": datetime.now().isoformat(),
            "expiration_date": (datetime.now() + timedelta(days=30)).isoformat(),
            "pdf_path": pdf_path,
            "source_type": src_type,
            "threat_matched": threat_matched
        })
        
        report_id = os.path.splitext(filename)[0] 
        upload_to_os_lib(doc, report_id, "cti-reports")

        # å¦‚æœæ˜¯ Log æˆ– Manualï¼ŒåŒæ­¥åˆ° SOC Dashboard (Map Needs Data)
        if is_log or is_manual:
            soc_doc = doc.copy()
            first_ip = indicators.get("ipv4", [None])[0]
            soc_doc["source_ip"] = first_ip if first_ip else "Unknown"
            soc_doc["log_text"] = raw_content
            soc_doc["message"] = raw_content
            soc_doc["threat_matched"] = True 
            soc_doc["attack_type"] = extracted.get("attack_type", "High Confidence Threat")
            soc_doc["severity"] = "Critical" if confidence >= 90 else "High"
            soc_doc["mitigation_status"] = "Blocked  "
            
            upload_to_os_lib(soc_doc, f"log_{report_id}", "security-logs-knn")
            logger.info(f"  Synced to SOC Dashboard (security-logs-knn)")

    # 3. å™ªéŸ³éæ¿¾ / ä½ä¿¡å¿ƒ Log
    elif is_log and confidence < 40 and not force_human_review:
        logger.info(f"  Low confidence Log ({confidence}%). Archiving.")

    # 3. äººå·¥å¯©æ ¸é€šé“ (Human-in-the-Loop)
    else:
        # é‚Šç·£æ¡ˆä¾‹ï¼Œä¾‹å¦‚æœ‰æƒ…å ±ä½† AI ä¸å¤ªç¢ºå®šï¼Œä¸Ÿçµ¦äººå·¥å¯©æ ¸
        if is_log:
            source_type = "suspicious_log"
            log_msg = f"ğŸ¤” Suspicious Log ({confidence}%). Sending to Human Review..."
        elif is_premium_feed:
            source_type = "unverified_cti_feed"
            log_msg = f"ğŸ¤” Unverified Premium CTI ({confidence}%). Sending to Human Review..."
        else:
            source_type = "manual"
            log_msg = f"ğŸ¤” Ambiguous Manual Upload ({confidence}%). Sending to Human Review..."
            
        logger.info(log_msg)
        
        insert_task(
            filename=filename,
            source_type=source_type,
            raw_content=safe_content,
            analysis_json=extracted,
            confidence=confidence
        )
        
        # Optimization: Also index to security-logs-knn for Dashboard visibility (e.g. Guardrail Downgrades)
        if force_human_review or confidence > 50:
             # Create a record for dashboard visibility
             soc_doc = extracted.copy()
             soc_doc.update({
                "filename": filename,
                "timestamp": datetime.now().isoformat(),
                "source_ip": indicators.get("ipv4", [None])[0] or "Unknown",
                "log_text": safe_content,
                "message": safe_content,
                "threat_matched": True, # Keep it visible as threat
                "attack_type": extracted.get("attack_type", "Suspicious Activity"),
                "severity": "Medium",
                "mitigation_status": "Pending Manual Approval â³"
             })
             # Use a distinct ID to avoid overwriting if approved later (though dashboard usually filters by ID)
             report_id = os.path.splitext(filename)[0]
             upload_to_os_lib(soc_doc, f"log_{report_id}", "security-logs-knn")
             logger.info(f"  Synced to SOC Dashboard (security-logs-knn) as Pending.")
    # ================= å°‡åˆ†æçµæœå­˜ç‚º JSON å‚™ä»½ =================
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # å¦‚æœæ˜¯ä¸²æµæ¨¡å¼ï¼Œfilename å·²ç¶“åŒ…å«æ™‚é–“æˆ³ï¼Œé€™è£¡å†åŠ ä¸€æ¬¡å‰ç¶´æˆ–æ˜¯å¯ä»¥ç°¡åŒ–
        json_filename = f"{timestamp}_{os.path.splitext(filename)[0]}.json"
        json_path = os.path.join(PROCESSED_DIR, json_filename)
        
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(extracted, f, indent=4, ensure_ascii=False)
            
        logger.info(f"  Analysis JSON saved to: {json_path}")
    except Exception as e:
        logger.error(f"  Failed to save JSON file: {e}")

    # ================= æ­¸æª” (åªé‡å°æª”æ¡ˆæ¨¡å¼) =================
    if file_path:
        move_to_processed(file_path, filename)


# --- Master: ç›£æ§æª”æ¡ˆä¸¦ç™¼é€ä»»å‹™ ---
def run_master():
    logger.info("  CTI Master Started. Monitoring data/input/ ...")
    
    # å•Ÿå‹•èƒŒæ™¯æ›´æ–°åŸ·è¡Œç·’ (æ’ç¨‹å™¨)
    updater_thread = threading.Thread(target=run_scheduler_thread, daemon=True)
    updater_thread.start()
    
    while True: # ç¬¬ä¸€å±¤ï¼šé€£ç·šé‡è©¦
        connection = None
        try:
            connection, channel = get_rabbitmq_connection()
            
            # å®£å‘Š Exchange å’Œ Queue æ‹“æ¨¸
            # ç‚ºäº†ç¢ºä¿ Master ç™¼å‡ºå»çš„ä»»å‹™ï¼Œè·Ÿ Fluent Bit ç™¼å‡ºå»çš„ Logï¼Œéƒ½èµ°åŒä¸€æ¢è·¯
            channel.exchange_declare(exchange='cti_exchange', exchange_type='direct')
            channel.queue_declare(queue=RABBITMQ_QUEUE, durable=True)
            channel.queue_bind(exchange='cti_exchange', queue=RABBITMQ_QUEUE, routing_key='cti_queue')
            
            logger.info("  Master connected to RabbitMQ (Binding: cti_exchange -> cti_queue).")

            while True: # ç¬¬äºŒå±¤ï¼šç›£æ§è¿´åœˆ
                # æª¢æŸ¥é€£ç·š
                if connection.is_closed:
                    raise pika.exceptions.AMQPConnectionError("Connection closed")

                # æƒæ txt æª”æ¡ˆ
                files = glob.glob(os.path.join(INPUT_DIR, "*.txt"))
                for file_path in files:
                    filename = os.path.basename(file_path)
                    
                    # è·³éå·²ç¶“è¢«é–å®šçš„æª”æ¡ˆ
                    if filename.endswith(".processing"):
                        continue

                    logger.info(f"  Found new file: {filename}")
                    
                    # é–å®šæª”æ¡ˆ (æ”¹å)
                    processing_path = file_path + ".processing"
                    try:
                        os.rename(file_path, processing_path)
                    except OSError:
                        continue # å¯èƒ½è¢«å…¶ä»– process æ¶èµ°äº†

                    # ç™¼é€ä»»å‹™ (Multi-Tenancy Simulation)
                    tenant = "default"
                    if filename.startswith("alpha_"): tenant = "tenant_alpha"
                    elif filename.startswith("beta_"): tenant = "tenant_beta"
                    
                    task_payload = json.dumps({
                        "file_path": processing_path,
                        "filename": filename,
                        "tenant_id": tenant
                    })
                    
                    try:
                        # ç™¼é€è‡³æŒ‡å®šçš„ Exchange å’Œ Routing Key
                        channel.basic_publish(
                            exchange='cti_exchange',  # æŒ‡å®šäº¤æ›æ©Ÿ
                            routing_key='cti_queue',  # æŒ‡å®šè·¯ç”±éµ (è·Ÿ Fluent Bit ä¸€æ¨£)
                            body=task_payload,
                            properties=pika.BasicProperties(delivery_mode=2) 
                        )
                        logger.info(f"  Task queued: {filename}")
                        
                    except (pika.exceptions.AMQPError, pika.exceptions.StreamLostError) as e:
                        # é€™æ˜¯é€£ç·šå•é¡Œï¼Œéœ€è¦è®“å¤–å±¤è¿´åœˆé‡é€£
                        logger.error(f"  RabbitMQ Error during publish: {e}")
                        os.rename(processing_path, file_path) # å¾©åŸæª”æ¡ˆ
                        raise e # æ‹‹å‡ºéŒ¯èª¤è®“å¤–å±¤ while True é‡é€£
                    except Exception as e:
                        # é€™æ˜¯ç¨‹å¼é‚è¼¯æˆ–å…¶ä»–å•é¡Œ (ä¾‹å¦‚ JSON éŒ¯èª¤)ï¼Œä¸è¦è®“ Master å´©æ½°é‡å•Ÿ
                        logger.error(f"  Logical Error during publish: {e}")
                        os.rename(processing_path, file_path)
                        # ä¸è¦ raiseï¼Œè®“å®ƒç¹¼çºŒè™•ç†ä¸‹ä¸€å€‹æª”æ¡ˆï¼Œé¿å…å¡æ­»

                time.sleep(2) # è¼ªè©¢é–“éš”

        except (pika.exceptions.AMQPError, pika.exceptions.AMQPConnectionError) as e:
            logger.error(f"  Master connection lost: {e}. Retrying in 5s...")
            time.sleep(5)
        except Exception as e:
            logger.error(f"  Master unexpected error: {e}. Restarting in 10s...")
            time.sleep(10)

# --- Worker: å¾ Queue é ˜ä»»å‹™ ---
def safe_process_task(ch, method, properties, body, llm, enricher, cve_enricher, audit_logger):
    """
    Wrapper to handle task processing with error handling and DLQ support.
    Expected to be used as a RabbitMQ callback.
    """
    try:
        # è§£æè¨Šæ¯ (å¯èƒ½æ˜¯ Master çš„æª”æ¡ˆè·¯å¾‘ï¼Œä¹Ÿå¯èƒ½æ˜¯ Fluent Bit çš„ JSON)
        task_payload = json.loads(body)
        
        # å‘¼å«é€šç”¨çš„è™•ç†å‡½å¼
        process_task(task_payload, llm, enricher, cve_enricher, audit_logger)
        
        # ä»»å‹™æˆåŠŸï¼Œç™¼é€ ACK
        ch.basic_ack(delivery_tag=method.delivery_tag)

    except LocalLLMCriticalError as e:
        logger.critical(f"ğŸ›‘ [PRIVACY SHIELD ACTIVATED] Task blocked to prevent data leak! Error: {e}")
        # Send to specific DLQ for Privacy Violations
        failed_dir = "data/failed_tasks/privacy_blocked"
        os.makedirs(failed_dir, exist_ok=True)
        try:
            with open(f"{failed_dir}/blocked_{int(time.time())}.json", "w") as f:
                content = body.decode('utf-8') if isinstance(body, bytes) else str(body)
                f.write(content)
        except: pass
        
        # Acknowledge to remove from queue (it's handled by DLQ)
        ch.basic_ack(delivery_tag=method.delivery_tag)

    except Exception as e:
        logger.error(f"  Worker task error: {e}")
        # å‚™ä»½å¤±æ•—çš„ä»»å‹™åˆ°æœ¬åœ°ç«¯ (Optimization 4: DLQ)
        failed_dir = "data/failed_tasks"
        os.makedirs(failed_dir, exist_ok=True)
        try:
            with open(f"{failed_dir}/failed_{int(time.time())}.json", "w") as f:
                # body is bytes, decode it
                content = body.decode('utf-8') if isinstance(body, bytes) else str(body)
                f.write(content)
        except Exception as write_err:
             logger.error(f"  Failed to write to DLQ: {write_err}")

        # é¿å…è¨Šæ¯å¡æ­»ï¼Œé¸æ“‡ ACK ä¸¦è¨˜éŒ„éŒ¯èª¤
        ch.basic_ack(delivery_tag=method.delivery_tag)

def run_worker():
    logger.info("  CTI Worker Started. Waiting for tasks...")
    llm = LLMClient()
    enricher = EnrichmentEngine()
    cve_enricher = CVEEnricher()
    audit_logger = AuditLogger()
    
    while True:
        try:
            connection, channel = get_rabbitmq_connection()
            
            # å®£å‘Š Exchange èˆ‡ Queue ç¶å®š (è·Ÿ Master/Fluent Bit ä¸€è‡´)
            channel.exchange_declare(exchange='cti_exchange', exchange_type='direct')
            channel.queue_declare(queue=RABBITMQ_QUEUE, durable=True)
            channel.queue_bind(exchange='cti_exchange', queue=RABBITMQ_QUEUE, routing_key='cti_queue')
            
            channel.basic_qos(prefetch_count=1)
            logger.info("  Worker connected & listening on 'cti_queue'...")

            def callback(ch, method, properties, body):
                safe_process_task(ch, method, properties, body, llm, enricher, cve_enricher, audit_logger)

            channel.basic_consume(queue=RABBITMQ_QUEUE, on_message_callback=callback)
            channel.start_consuming()

        except Exception as e:
            logger.error(f"  Worker error: {e}. Restarting in 5s...")
            time.sleep(5)

if __name__ == "__main__":
    ensure_dirs()
    if ROLE == 'master':
        run_master()
    else:
        run_worker()